{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My_CI_Project_DT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPoNdaDemamBYngk53BcR57",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammad-nahid-hossain/MSc.-Projects-Part-2/blob/main/My_CI_Project_DT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pyKAT2ydyIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dcda01d-c442-4820-e30a-4ae5b780113b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My0Euq482mI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "517a7f6a-16f8-435a-9f77-7b5dd2a77ccd"
      },
      "source": [
        "!ls \"/content/drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 2014_Bodily_Maps_of_Emotions.mat\n",
            "'2019110211_Hossain Mohammad Nahid.gdoc'\n",
            " Books\n",
            "'Books(islamic)'\n",
            "'Bsc Thesis'\n",
            " CERTIFICATES\n",
            "'Colab Notebooks'\n",
            " Coursera\n",
            " CV\n",
            "'Data Acquisition for research work'\n",
            " DeepLearningBook.pdf\n",
            "'Dream forest tour'\n",
            "'Getting started.pdf'\n",
            "'GME transaction'\n",
            " Hmmmmm.gsheet\n",
            "'How to install cuda 10.1 in Ubuntu 18.04.zip'\n",
            " IMG_4717.JPG\n",
            " IMG_4719.JPG\n",
            " lecture_1.pdf\n",
            " lecture_2.pdf\n",
            " lecture_3.pdf\n",
            " lecture_4.pdf\n",
            " Msc\n",
            " Neural-Network-based-finger-counting-technique.pdf\n",
            "'New Doc 2019-09-03 20.05.57.jpg'\n",
            " Paper\n",
            "'PhD Application'\n",
            "'PhD Application Pack'\n",
            "'Planning Document.docx'\n",
            "'Planning Document.odt'\n",
            "'Planning Document.pdf'\n",
            "'Snow fall video'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d-08cgllUFp"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.metrics import confusion_matrix \n",
        "#from sklearn.cross_validation import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hMvFrESldxE"
      },
      "source": [
        "# Function importing Dataset \n",
        "def importdata():\n",
        "    CI_data = pd.read_csv('/content/drive/My Drive/Msc/Msc Thesis/Coding Documents/AFS/DT/My_Project_CI_data.csv') \n",
        "    # Printing the dataswet shape \n",
        "    print (\"Dataset Length: \", len(CI_data)) \n",
        "    print (\"Dataset Shape: \", CI_data.shape) \n",
        "    \n",
        "    # Printing the dataset obseravtions \n",
        "    print (\"Dataset: \",CI_data.head())\n",
        "    return CI_data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_MKu64xlwng"
      },
      "source": [
        "# Function to split the dataset \n",
        "def splitdataset(CI_data): \n",
        "  \n",
        "    # Separating the target variable \n",
        "    X = CI_data.values[:, 0:4] \n",
        "    Y = CI_data.values[:, 4] \n",
        "  \n",
        "    # Splitting the dataset into train and test \n",
        "    X_train, X_test, y_train, y_test = train_test_split(  \n",
        "    X, Y, test_size = 0.3, random_state = 100) \n",
        "      \n",
        "    return X, Y, X_train, X_test, y_train, y_test "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbuN43e9l5xP"
      },
      "source": [
        "# Function to perform training with giniIndex. \n",
        "def train_using_gini(X_train, X_test, y_train): \n",
        "  \n",
        "    # Creating the classifier object \n",
        "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
        "            random_state = 100,max_depth=7, min_samples_leaf=1) \n",
        "  \n",
        "    # Performing training \n",
        "    clf_gini.fit(X_train, y_train) \n",
        "    return clf_gini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtYtdjQ9mCmK"
      },
      "source": [
        "# Function to perform training with entropy. \n",
        "def tarin_using_entropy(X_train, X_test, y_train): \n",
        "  \n",
        "    # Decision tree with entropy \n",
        "    clf_entropy = DecisionTreeClassifier( \n",
        "            criterion = \"entropy\", random_state = 100, \n",
        "            max_depth = 4, min_samples_leaf = 1) \n",
        "  \n",
        "    # Performing training \n",
        "    clf_entropy.fit(X_train, y_train) \n",
        "    return clf_entropy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMCWlfslmHTe"
      },
      "source": [
        "# Function to make predictions \n",
        "def prediction(X_test, clf_object): \n",
        "  \n",
        "    # Predicton on test with giniIndex \n",
        "    y_pred = clf_object.predict(X_test) \n",
        "    print(\"Predicted values:\") \n",
        "    print(y_pred) \n",
        "    return y_pred "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eBF6b8fmLYG"
      },
      "source": [
        "# Function to calculate accuracy \n",
        "def cal_accuracy(y_test, y_pred): \n",
        "      \n",
        "    print(\"Confusion Matrix: \", \n",
        "        confusion_matrix(y_test, y_pred)) \n",
        "      \n",
        "    print (\"Accuracy : \", \n",
        "    accuracy_score(y_test,y_pred)*100) \n",
        "      \n",
        "    print(\"Report : \", \n",
        "    classification_report(y_test, y_pred)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WMYBLqwmPCn"
      },
      "source": [
        "# Driver code \n",
        "def main(): \n",
        "      \n",
        "    # Building Phase \n",
        "    data = importdata() \n",
        "    X, Y, X_train, X_test, y_train, y_test = splitdataset(data) \n",
        "    clf_gini = train_using_gini(X_train, X_test, y_train) \n",
        "    clf_entropy = tarin_using_entropy(X_train, X_test, y_train) \n",
        "      \n",
        "    # Operational Phase \n",
        "    print(\"Results Using Gini Index:\") \n",
        "      \n",
        "    # Prediction using gini \n",
        "    y_pred_gini = prediction(X_test, clf_gini) \n",
        "    cal_accuracy(y_test, y_pred_gini) \n",
        "      \n",
        "    print(\"Results Using Entropy:\") \n",
        "    # Prediction using entropy \n",
        "    y_pred_entropy = prediction(X_test, clf_entropy) \n",
        "    cal_accuracy(y_test, y_pred_entropy) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWnag5tJmUAP",
        "outputId": "1cb63a65-53d5-4d6c-9cd0-987f5b1d56dc"
      },
      "source": [
        "# Calling main function \n",
        "if __name__==\"__main__\": \n",
        "    main() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Length:  5475\n",
            "Dataset Shape:  (5475, 5)\n",
            "Dataset:     TotalTime       AVG      Energy  Step  Group\n",
            "0         12  1.500000  302.500000   605      3\n",
            "1         13  2.166667  183.333333   550      3\n",
            "2         10  1.428571  183.333333   550      3\n",
            "3         12  1.500000  183.333333   550      3\n",
            "4         10  1.250000  201.666667   605      3\n",
            "Results Using Gini Index:\n",
            "Predicted values:\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "Confusion Matrix:  [[1095   13    4    0]\n",
            " [ 194   95    1   24]\n",
            " [ 124   11    0    1]\n",
            " [  26   39    0   16]]\n",
            "Accuracy :  73.40231284236154\n",
            "Report :                precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.98      0.86      1112\n",
            "         1.0       0.60      0.30      0.40       314\n",
            "         2.0       0.00      0.00      0.00       136\n",
            "         3.0       0.39      0.20      0.26        81\n",
            "\n",
            "    accuracy                           0.73      1643\n",
            "   macro avg       0.44      0.37      0.38      1643\n",
            "weighted avg       0.65      0.73      0.67      1643\n",
            "\n",
            "Results Using Entropy:\n",
            "Predicted values:\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "Confusion Matrix:  [[1105    7    0    0]\n",
            " [ 198  116    0    0]\n",
            " [ 124   12    0    0]\n",
            " [  20   55    0    6]]\n",
            "Accuracy :  74.68046256847231\n",
            "Report :                precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.99      0.86      1112\n",
            "         1.0       0.61      0.37      0.46       314\n",
            "         2.0       0.00      0.00      0.00       136\n",
            "         3.0       1.00      0.07      0.14        81\n",
            "\n",
            "    accuracy                           0.75      1643\n",
            "   macro avg       0.59      0.36      0.37      1643\n",
            "weighted avg       0.68      0.75      0.68      1643\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}